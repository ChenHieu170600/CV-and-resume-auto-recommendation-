{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tOnGtENnz1-M",
        "outputId": "4476b3b3-e912-4b99-cecb-c5cd9590389e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Godde\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "C:\\Users\\Godde\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
            "C:\\Users\\Godde\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Resume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Category                                             Resume\n",
              "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
              "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
              "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
              "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
              "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import Dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn7XuTlkz6Jc",
        "outputId": "78a9c568-e57b-4fef-f940-89ba4b8f883a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['skills', 'programming', 'languages', 'python', 'pandas', 'numpy', 'scipy', 'scikit', 'learn', 'matplotlib', 'sql', 'java', 'javascript', 'jquery', 'machine', 'learning', 'regression', 'svm', 'naa', 've', 'bayes', 'knn', 'random', 'forest', 'decision', 'trees', 'boosting', 'techniques', 'cluster', 'analysis', 'word', 'embedding', 'sentiment', 'analysis', 'natural', 'language', 'processing', 'dimensionality', 'reduction', 'topic', 'modelling', 'lda', 'nmf', 'pca', 'neural', 'nets', 'database', 'visualizations', 'mysql', 'sqlserver', 'cassandra', 'hbase', 'elasticsearch', 'js', 'dc', 'js', 'plotly', 'kibana', 'matplotlib', 'ggplot', 'tableau', 'others', 'regular', 'expression', 'html', 'css', 'angular', 'logstash', 'kafka', 'python', 'flask', 'git', 'docker', 'computer', 'vision', 'open', 'cv', 'and', 'understanding', 'of', 'deep', 'learning', 'education', 'details', 'data', 'science', 'assurance', 'associate', 'data', 'science', 'assurance', 'associate', 'ernst', 'young', 'llp', 'skill', 'details', 'javascript', 'exprience', 'months', 'jquery', 'exprience', 'months', 'python', 'exprience', 'monthscompany', 'details', 'company', 'ernst', 'young', 'llp', 'description', 'fraud', 'investigations', 'and', 'dispute', 'services', 'assurance', 'technology', 'assisted', 'review', 'tar', 'technology', 'assisted', 'review', 'assists', 'in', 'accelerating', 'the', 'review', 'process', 'and', 'run', 'analytics', 'and', 'generate', 'reports', 'core', 'member', 'of', 'team', 'helped', 'in', 'developing', 'automated', 'review', 'platform', 'tool', 'from', 'scratch', 'for', 'assisting', 'discovery', 'domain', 'this', 'tool', 'implements', 'predictive', 'coding', 'and', 'topic', 'modelling', 'by', 'automating', 'reviews', 'resulting', 'in', 'reduced', 'labor', 'costs', 'and', 'time', 'spent', 'during', 'the', 'lawyers', 'review', 'understand', 'the', 'end', 'to', 'end', 'flow', 'of', 'the', 'solution', 'doing', 'research', 'and', 'development', 'for', 'classification', 'models', 'predictive', 'analysis', 'and', 'mining', 'of', 'the', 'information', 'present', 'in', 'text', 'data', 'worked', 'on', 'analyzing', 'the', 'outputs', 'and', 'precision', 'monitoring', 'for', 'the', 'entire', 'tool', 'tar', 'assists', 'in', 'predictive', 'coding', 'topic', 'modelling', 'from', 'the', 'evidence', 'by', 'following', 'ey', 'standards', 'developed', 'the', 'classifier', 'models', 'in', 'order', 'to', 'identify', 'red', 'flags', 'and', 'fraud', 'related', 'issues', 'tools', 'technologies', 'python', 'scikit', 'learn', 'tfidf', 'word', 'vec', 'doc', 'vec', 'cosine', 'similarity', 'naa', 've', 'bayes', 'lda', 'nmf', 'for', 'topic', 'modelling', 'vader', 'and', 'text', 'blob', 'for', 'sentiment', 'analysis', 'matplot', 'lib', 'tableau', 'dashboard', 'for', 'reporting', 'multiple', 'data', 'science', 'and', 'analytic', 'projects', 'usa', 'clients', 'text', 'analytics', 'motor', 'vehicle', 'customer', 'review', 'data', 'received', 'customer', 'feedback', 'survey', 'data', 'for', 'past', 'one', 'year', 'performed', 'sentiment', 'positive', 'negative', 'neutral', 'and', 'time', 'series', 'analysis', 'on', 'customer', 'comments', 'across', 'all', 'categories', 'created', 'heat', 'map', 'of', 'terms', 'by', 'survey', 'category', 'based', 'on', 'frequency', 'of', 'words', 'extracted', 'positive', 'and', 'negative', 'words', 'across', 'all', 'the', 'survey', 'categories', 'and', 'plotted', 'word', 'cloud', 'created', 'customized', 'tableau', 'dashboards', 'for', 'effective', 'reporting', 'and', 'visualizations', 'chatbot', 'developed', 'user', 'friendly', 'chatbot', 'for', 'one', 'of', 'our', 'products', 'which', 'handle', 'simple', 'questions', 'about', 'hours', 'of', 'operation', 'reservation', 'options', 'and', 'so', 'on', 'this', 'chat', 'bot', 'serves', 'entire', 'product', 'related', 'questions', 'giving', 'overview', 'of', 'tool', 'via', 'qa', 'platform', 'and', 'also', 'give', 'recommendation', 'responses', 'so', 'that', 'user', 'question', 'to', 'build', 'chain', 'of', 'relevant', 'answer', 'this', 'too', 'has', 'intelligence', 'to', 'build', 'the', 'pipeline', 'of', 'questions', 'as', 'per', 'user', 'requirement', 'and', 'asks', 'the', 'relevant', 'recommended', 'questions', 'tools', 'technologies', 'python', 'natural', 'language', 'processing', 'nltk', 'spacy', 'topic', 'modelling', 'sentiment', 'analysis', 'word', 'embedding', 'scikit', 'learn', 'javascript', 'jquery', 'sqlserver', 'information', 'governance', 'organizations', 'to', 'make', 'informed', 'decisions', 'about', 'all', 'of', 'the', 'information', 'they', 'store', 'the', 'integrated', 'information', 'governance', 'portfolio', 'synthesizes', 'intelligence', 'across', 'unstructured', 'data', 'sources', 'and', 'facilitates', 'action', 'to', 'ensure', 'organizations', 'are', 'best', 'positioned', 'to', 'counter', 'information', 'risk', 'scan', 'data', 'from', 'multiple', 'sources', 'of', 'formats', 'and', 'parse', 'different', 'file', 'formats', 'extract', 'meta', 'data', 'information', 'push', 'results', 'for', 'indexing', 'elastic', 'search', 'and', 'created', 'customized', 'interactive', 'dashboards', 'using', 'kibana', 'preforming', 'rot', 'analysis', 'on', 'the', 'data', 'which', 'give', 'information', 'of', 'data', 'which', 'helps', 'identify', 'content', 'that', 'is', 'either', 'redundant', 'outdated', 'or', 'trivial', 'preforming', 'full', 'text', 'search', 'analysis', 'on', 'elastic', 'search', 'with', 'predefined', 'methods', 'which', 'can', 'tag', 'as', 'pii', 'personally', 'identifiable', 'information', 'social', 'security', 'numbers', 'addresses', 'names', 'etc', 'which', 'frequently', 'targeted', 'during', 'cyber', 'attacks', 'tools', 'technologies', 'python', 'flask', 'elastic', 'search', 'kibana', 'fraud', 'analytic', 'platform', 'fraud', 'analytics', 'and', 'investigative', 'platform', 'to', 'review', 'all', 'red', 'flag', 'cases', 'fap', 'is', 'fraud', 'analytics', 'and', 'investigative', 'platform', 'with', 'inbuilt', 'case', 'manager', 'and', 'suite', 'of', 'analytics', 'for', 'various', 'erp', 'systems', 'it', 'can', 'be', 'used', 'by', 'clients', 'to', 'interrogate', 'their', 'accounting', 'systems', 'for', 'identifying', 'the', 'anomalies', 'which', 'can', 'be', 'indicators', 'of', 'fraud', 'by', 'running', 'advanced', 'analytics', 'tools', 'technologies', 'html', 'javascript', 'sqlserver', 'jquery', 'css', 'bootstrap', 'node', 'js', 'js', 'dc', 'js']]\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "data = list(df['Resume'])\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "print(data_words[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjBZ7nWwz-Fk",
        "outputId": "c91abeb6-5307-4bec-9127-b0417e7032ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['skills', 'programming', 'languages', 'python', 'pandas', 'numpy', 'scipy', 'scikit_learn', 'matplotlib', 'sql', 'java', 'javascript', 'jquery', 'machine', 'learning', 'regression', 'svm', 'naa_ve', 'bayes', 'knn', 'random_forest', 'decision', 'trees', 'boosting', 'techniques', 'cluster', 'analysis', 'word_embedding', 'sentiment', 'analysis', 'natural_language_processing', 'dimensionality_reduction', 'topic_modelling', 'lda_nmf', 'pca', 'neural', 'nets', 'database', 'visualizations', 'mysql', 'sqlserver', 'cassandra', 'hbase', 'elasticsearch', 'js', 'dc', 'js', 'plotly', 'kibana', 'matplotlib', 'ggplot', 'tableau', 'others', 'regular', 'expression', 'html', 'css', 'angular', 'logstash', 'kafka', 'python', 'flask', 'git', 'docker', 'computer', 'vision', 'open_cv', 'and', 'understanding', 'of', 'deep', 'learning', 'education', 'details', 'data', 'science', 'assurance_associate', 'data', 'science', 'assurance_associate', 'ernst_young', 'llp', 'skill', 'details', 'javascript', 'exprience', 'months', 'jquery', 'exprience', 'months', 'python', 'exprience', 'monthscompany', 'details', 'company', 'ernst_young', 'llp', 'description', 'fraud', 'investigations', 'and', 'dispute', 'services', 'assurance', 'technology', 'assisted', 'review', 'tar', 'technology', 'assisted', 'review', 'assists', 'in', 'accelerating', 'the', 'review', 'process', 'and', 'run', 'analytics', 'and', 'generate', 'reports', 'core', 'member', 'of', 'team', 'helped', 'in', 'developing', 'automated', 'review', 'platform', 'tool', 'from', 'scratch', 'for', 'assisting', 'discovery', 'domain', 'this', 'tool', 'implements', 'predictive', 'coding', 'and', 'topic_modelling', 'by', 'automating', 'reviews', 'resulting', 'in', 'reduced', 'labor', 'costs', 'and', 'time', 'spent', 'during', 'the', 'lawyers', 'review', 'understand', 'the', 'end', 'to', 'end', 'flow', 'of', 'the', 'solution', 'doing', 'research', 'and', 'development', 'for', 'classification', 'models', 'predictive', 'analysis', 'and', 'mining', 'of', 'the', 'information', 'present', 'in', 'text', 'data', 'worked', 'on', 'analyzing', 'the', 'outputs', 'and', 'precision', 'monitoring', 'for', 'the', 'entire', 'tool', 'tar', 'assists', 'in', 'predictive', 'coding', 'topic_modelling', 'from', 'the', 'evidence', 'by', 'following', 'ey', 'standards', 'developed', 'the', 'classifier', 'models', 'in', 'order', 'to', 'identify', 'red', 'flags', 'and', 'fraud', 'related', 'issues', 'tools', 'technologies', 'python', 'scikit_learn', 'tfidf', 'word', 'vec', 'doc', 'vec', 'cosine_similarity', 'naa_ve', 'bayes', 'lda_nmf', 'for', 'topic_modelling', 'vader', 'and', 'text', 'blob', 'for', 'sentiment', 'analysis', 'matplot', 'lib', 'tableau', 'dashboard', 'for', 'reporting', 'multiple', 'data', 'science', 'and', 'analytic', 'projects', 'usa', 'clients', 'text', 'analytics', 'motor', 'vehicle', 'customer', 'review', 'data', 'received', 'customer', 'feedback', 'survey', 'data', 'for', 'past', 'one', 'year', 'performed', 'sentiment', 'positive_negative', 'neutral', 'and', 'time', 'series', 'analysis', 'on', 'customer', 'comments', 'across', 'all', 'categories', 'created', 'heat', 'map', 'of', 'terms', 'by', 'survey', 'category', 'based', 'on', 'frequency', 'of', 'words', 'extracted', 'positive', 'and', 'negative', 'words', 'across', 'all', 'the', 'survey', 'categories', 'and', 'plotted', 'word', 'cloud', 'created', 'customized', 'tableau', 'dashboards', 'for', 'effective', 'reporting', 'and', 'visualizations', 'chatbot', 'developed', 'user', 'friendly', 'chatbot', 'for', 'one', 'of', 'our', 'products', 'which', 'handle', 'simple', 'questions', 'about', 'hours', 'of', 'operation', 'reservation', 'options', 'and', 'so', 'on', 'this', 'chat_bot', 'serves', 'entire', 'product', 'related', 'questions', 'giving', 'overview', 'of', 'tool', 'via', 'qa', 'platform', 'and', 'also', 'give', 'recommendation', 'responses', 'so', 'that', 'user', 'question', 'to', 'build', 'chain', 'of', 'relevant', 'answer', 'this', 'too', 'has', 'intelligence', 'to', 'build', 'the', 'pipeline', 'of', 'questions', 'as', 'per', 'user', 'requirement', 'and', 'asks', 'the', 'relevant', 'recommended', 'questions', 'tools', 'technologies', 'python', 'natural_language_processing', 'nltk', 'spacy', 'topic_modelling', 'sentiment', 'analysis', 'word_embedding', 'scikit_learn', 'javascript', 'jquery', 'sqlserver', 'information', 'governance', 'organizations', 'to', 'make', 'informed', 'decisions', 'about', 'all', 'of', 'the', 'information', 'they', 'store', 'the', 'integrated', 'information', 'governance', 'portfolio', 'synthesizes', 'intelligence', 'across', 'unstructured', 'data', 'sources', 'and', 'facilitates', 'action', 'to', 'ensure', 'organizations', 'are', 'best', 'positioned', 'to', 'counter', 'information', 'risk', 'scan', 'data', 'from', 'multiple', 'sources', 'of', 'formats', 'and', 'parse', 'different', 'file', 'formats', 'extract', 'meta', 'data', 'information', 'push', 'results', 'for', 'indexing', 'elastic_search', 'and', 'created', 'customized', 'interactive', 'dashboards', 'using', 'kibana', 'preforming', 'rot', 'analysis', 'on', 'the', 'data', 'which', 'give', 'information', 'of', 'data', 'which', 'helps', 'identify', 'content', 'that', 'is', 'either', 'redundant', 'outdated', 'or', 'trivial', 'preforming', 'full', 'text', 'search', 'analysis', 'on', 'elastic_search', 'with', 'predefined', 'methods', 'which', 'can', 'tag', 'as', 'pii', 'personally', 'identifiable', 'information', 'social', 'security', 'numbers', 'addresses', 'names', 'etc', 'which', 'frequently', 'targeted', 'during', 'cyber', 'attacks', 'tools', 'technologies', 'python', 'flask', 'elastic_search', 'kibana', 'fraud', 'analytic', 'platform', 'fraud', 'analytics', 'and', 'investigative', 'platform', 'to', 'review', 'all', 'red', 'flag', 'cases', 'fap', 'is', 'fraud', 'analytics', 'and', 'investigative', 'platform', 'with', 'inbuilt', 'case', 'manager', 'and', 'suite', 'of', 'analytics', 'for', 'various', 'erp', 'systems', 'it', 'can', 'be', 'used', 'by', 'clients', 'to', 'interrogate', 'their', 'accounting', 'systems', 'for', 'identifying', 'the', 'anomalies', 'which', 'can', 'be', 'indicators', 'of', 'fraud', 'by', 'running', 'advanced', 'analytics', 'tools', 'technologies', 'html', 'javascript', 'sqlserver', 'jquery', 'css', 'bootstrap', 'node_js', 'js', 'dc', 'js']\n"
          ]
        }
      ],
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[data_words[0]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_X2vRNh0D-n",
        "outputId": "3d38e645-b060-4199-a1a4-cbf4d2749a06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Godde\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xm8K3l2C0Rw8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['skill', 'programming', 'language', 'panda', 'numpy', 'scipy', 'matplotlib', 'learn', 'regression', 'svm', 'naa', 'baye', 'knn', 'random_for', 'decision', 'tree', 'boost', 'technique', 'cluster', 'analysis', 'word_embedding', 'sentiment', 'analysis', 'natural_language', 'process', 'dimensionality_reduction', 'topic_modelling', 'lda_nmf', 'pca', 'neural', 'net', 'database', 'visualization', 'mysql', 'sqlserver', 'hbase', 'elasticsearch', 'plotly', 'other', 'regular', 'expression', 'css', 'angular', 'logstash', 'kafka', 'computer', 'vision', 'open_cv', 'understand', 'deep', 'learn', 'education', 'detail', 'data', 'science', 'data', 'science', 'llp', 'skill', 'javascript', 'month', 'monthscompany', 'detail', 'company', 'llp', 'description', 'fraud', 'investigation', 'dispute', 'service', 'assurance', 'technology', 'assist', 'review', 'tar', 'technology', 'assist', 'review', 'assist', 'accelerate', 'review', 'process', 'run', 'analytic', 'generate', 'report', 'core', 'member', 'team', 'help', 'develop', 'automate', 'review', 'platform', 'tool', 'scratch', 'assist', 'discovery', 'domain', 'tool', 'implement', 'predictive', 'code', 'topic_modelle', 'automate', 'review', 'result', 'reduce', 'labor', 'cost', 'time', 'spend', 'lawyer', 'review', 'understand', 'end', 'end', 'flow', 'solution', 'research', 'development', 'classification', 'model', 'predictive', 'analysis', 'mining', 'information', 'present', 'text', 'datum', 'work', 'analyze', 'output', 'precision', 'monitor', 'entire', 'tool', 'tar', 'assist', 'predictive', 'code', 'topic_modelle', 'evidence', 'follow', 'standard', 'develop', 'classifier', 'model', 'order', 'identify', 'red', 'flag', 'fraud', 'related', 'issue', 'tool', 'technologie', 'tfidf', 'word', 'vec', 'doc', 'vec', 'cosine_similarity', 'naa', 'baye', 'lda_nmf', 'topic_modelle', 'vader', 'text', 'blob', 'sentiment', 'analysis', 'dashboard', 'report', 'multiple', 'datum', 'science', 'analytic', 'project', 'usa', 'client', 'text', 'analytic', 'motor', 'vehicle', 'customer', 'review', 'datum', 'receive', 'customer', 'feedback', 'survey', 'datum', 'year', 'perform', 'sentiment', 'positive_negative', 'neutral', 'time', 'series', 'analysis', 'customer', 'comment', 'category', 'create', 'heat', 'map', 'term', 'survey', 'category', 'base', 'frequency', 'word', 'extract', 'positive_negative', 'word', 'survey', 'category', 'plot', 'word', 'cloud', 'create', 'customize', 'dashboard', 'effective', 'reporting', 'visualization', 'chatbot', 'develop', 'user', 'friendly', 'product', 'handle', 'simple', 'question', 'hour', 'operation', 'reservation', 'option', 'serve', 'entire', 'product', 'related', 'question', 'give', 'overview', 'tool', 'qa', 'platform', 'also', 'give', 'recommendation', 'response', 'user', 'question', 'build', 'chain', 'relevant', 'answer', 'intelligence', 'build', 'pipeline', 'question', 'user', 'requirement', 'ask', 'relevant', 'recommended', 'question', 'tool', 'technology', 'python', 'processing', 'nltk', 'spacy', 'topic_modelling', 'sentiment', 'analysis', 'word_embedde', 'scikit_learn', 'javascript', 'jquery', 'sqlserver', 'information', 'governance', 'organization', 'make', 'informed', 'decision', 'information', 'store', 'integrate', 'information', 'governance', 'portfolio', 'synthesize', 'intelligence', 'unstructured', 'datum', 'source', 'facilitate', 'action', 'ensure', 'organization', 'good', 'position', 'counter', 'information', 'risk', 'multiple', 'source', 'format', 'parse', 'different', 'file', 'format', 'extract', 'meta', 'datum', 'information', 'push', 'result', 'indexing', 'elastic_search', 'create', 'customize', 'interactive', 'dashboard', 'use', 'preform', 'rot', 'analysis', 'datum', 'give', 'information', 'datum', 'help', 'identify', 'content', 'redundant', 'outdated', 'trivial', 'preform', 'full', 'text', 'search', 'analysis', 'elastic_search', 'predefine', 'method', 'tag', 'pii', 'personally', 'identifiable', 'information', 'social', 'security', 'number', 'address', 'name', 'frequently', 'target', 'cyber', 'attack', 'tool', 'technology', 'fraud', 'analytic', 'platform', 'fraud', 'analytic', 'investigative', 'platform', 'review', 'red', 'flag', 'case', 'fap', 'fraud', 'analytic', 'investigative', 'platform', 'inbuilt', 'case', 'manager', 'suite', 'analytic', 'various', 'system', 'use', 'client', 'interrogate', 'accounting', 'system', 'identify', 'anomaly', 'indicator', 'fraud', 'run', 'advanced', 'analytic', 'tool', 'technology', 'bootstrap', 'node', 'j']]\n"
          ]
        }
      ],
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "import spacy\n",
        "\n",
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "\n",
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joO6Loxu0SIS",
        "outputId": "22dd380a-e8e7-4c01-84b9-b27974ef0d07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 8), (7, 8), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 5), (14, 1), (15, 1), (16, 2), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 2), (23, 2), (24, 3), (25, 1), (26, 1), (27, 1), (28, 1), (29, 2), (30, 1), (31, 1), (32, 2), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 3), (42, 1), (43, 3), (44, 2), (45, 1), (46, 3), (47, 2), (48, 1), (49, 8), (50, 2), (51, 1), (52, 1), (53, 2), (54, 3), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 2), (65, 1), (66, 2), (67, 1), (68, 2), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 2), (77, 1), (78, 1), (79, 2), (80, 6), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 3), (87, 1), (88, 2), (89, 1), (90, 1), (91, 1), (92, 2), (93, 1), (94, 1), (95, 3), (96, 1), (97, 1), (98, 1), (99, 1), (100, 8), (101, 1), (102, 1), (103, 2), (104, 1), (105, 1), (106, 1), (107, 2), (108, 1), (109, 1), (110, 2), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 2), (118, 2), (119, 2), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 2), (130, 1), (131, 1), (132, 1), (133, 1), (134, 2), (135, 1), (136, 2), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 2), (151, 1), (152, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 1), (162, 5), (163, 1), (164, 1), (165, 1), (166, 1), (167, 2), (168, 1), (169, 1), (170, 3), (171, 2), (172, 1), (173, 2), (174, 1), (175, 2), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 5), (182, 1), (183, 1), (184, 1), (185, 1), (186, 2), (187, 1), (188, 1), (189, 1), (190, 1), (191, 2), (192, 2), (193, 2), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 2), (200, 8), (201, 1), (202, 1), (203, 2), (204, 3), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 4), (211, 1), (212, 1), (213, 1), (214, 1), (215, 2), (216, 1), (217, 1), (218, 2), (219, 1), (220, 1), (221, 2), (222, 1), (223, 1), (224, 1), (225, 3), (226, 1), (227, 1), (228, 2), (229, 1), (230, 2), (231, 1), (232, 1), (233, 1), (234, 1), (235, 5), (236, 1), (237, 4), (238, 1), (239, 2), (240, 8), (241, 3), (242, 2), (243, 1), (244, 1), (245, 2), (246, 1), (247, 1), (248, 2), (249, 3), (250, 1), (251, 1), (252, 2), (253, 1), (254, 1), (255, 2), (256, 4), (257, 1), (258, 1), (259, 1), (260, 1)]]\n"
          ]
        }
      ],
      "source": [
        "import gensim.corpora as corpora\n",
        "\n",
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gN3_0RT0XXo",
        "outputId": "c54ceb01-d346-4dee-d4de-0e8215e525a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[('accelerate', 1),\n",
              "  ('accounting', 1),\n",
              "  ('action', 1),\n",
              "  ('address', 1),\n",
              "  ('advanced', 1),\n",
              "  ('also', 1),\n",
              "  ('analysis', 8),\n",
              "  ('analytic', 8),\n",
              "  ('analyze', 1),\n",
              "  ('angular', 1),\n",
              "  ('anomaly', 1),\n",
              "  ('answer', 1),\n",
              "  ('ask', 1),\n",
              "  ('assist', 5),\n",
              "  ('assurance', 1),\n",
              "  ('attack', 1),\n",
              "  ('automate', 2),\n",
              "  ('base', 1),\n",
              "  ('baye', 2),\n",
              "  ('blob', 1),\n",
              "  ('boost', 1),\n",
              "  ('bootstrap', 1),\n",
              "  ('build', 2),\n",
              "  ('case', 2),\n",
              "  ('category', 3),\n",
              "  ('chain', 1),\n",
              "  ('chatbot', 1),\n",
              "  ('classification', 1),\n",
              "  ('classifier', 1),\n",
              "  ('client', 2),\n",
              "  ('cloud', 1),\n",
              "  ('cluster', 1),\n",
              "  ('code', 2),\n",
              "  ('comment', 1),\n",
              "  ('company', 1),\n",
              "  ('computer', 1),\n",
              "  ('content', 1),\n",
              "  ('core', 1),\n",
              "  ('cosine_similarity', 1),\n",
              "  ('cost', 1),\n",
              "  ('counter', 1),\n",
              "  ('create', 3),\n",
              "  ('css', 1),\n",
              "  ('customer', 3),\n",
              "  ('customize', 2),\n",
              "  ('cyber', 1),\n",
              "  ('dashboard', 3),\n",
              "  ('data', 2),\n",
              "  ('database', 1),\n",
              "  ('datum', 8),\n",
              "  ('decision', 2),\n",
              "  ('deep', 1),\n",
              "  ('description', 1),\n",
              "  ('detail', 2),\n",
              "  ('develop', 3),\n",
              "  ('development', 1),\n",
              "  ('different', 1),\n",
              "  ('dimensionality_reduction', 1),\n",
              "  ('discovery', 1),\n",
              "  ('dispute', 1),\n",
              "  ('doc', 1),\n",
              "  ('domain', 1),\n",
              "  ('education', 1),\n",
              "  ('effective', 1),\n",
              "  ('elastic_search', 2),\n",
              "  ('elasticsearch', 1),\n",
              "  ('end', 2),\n",
              "  ('ensure', 1),\n",
              "  ('entire', 2),\n",
              "  ('evidence', 1),\n",
              "  ('expression', 1),\n",
              "  ('extract', 2),\n",
              "  ('facilitate', 1),\n",
              "  ('fap', 1),\n",
              "  ('feedback', 1),\n",
              "  ('file', 1),\n",
              "  ('flag', 2),\n",
              "  ('flow', 1),\n",
              "  ('follow', 1),\n",
              "  ('format', 2),\n",
              "  ('fraud', 6),\n",
              "  ('frequency', 1),\n",
              "  ('frequently', 1),\n",
              "  ('friendly', 1),\n",
              "  ('full', 1),\n",
              "  ('generate', 1),\n",
              "  ('give', 3),\n",
              "  ('good', 1),\n",
              "  ('governance', 2),\n",
              "  ('handle', 1),\n",
              "  ('hbase', 1),\n",
              "  ('heat', 1),\n",
              "  ('help', 2),\n",
              "  ('hour', 1),\n",
              "  ('identifiable', 1),\n",
              "  ('identify', 3),\n",
              "  ('implement', 1),\n",
              "  ('inbuilt', 1),\n",
              "  ('indexing', 1),\n",
              "  ('indicator', 1),\n",
              "  ('information', 8),\n",
              "  ('informed', 1),\n",
              "  ('integrate', 1),\n",
              "  ('intelligence', 2),\n",
              "  ('interactive', 1),\n",
              "  ('interrogate', 1),\n",
              "  ('investigation', 1),\n",
              "  ('investigative', 2),\n",
              "  ('issue', 1),\n",
              "  ('j', 1),\n",
              "  ('javascript', 2),\n",
              "  ('jquery', 1),\n",
              "  ('kafka', 1),\n",
              "  ('knn', 1),\n",
              "  ('labor', 1),\n",
              "  ('language', 1),\n",
              "  ('lawyer', 1),\n",
              "  ('lda_nmf', 2),\n",
              "  ('learn', 2),\n",
              "  ('llp', 2),\n",
              "  ('logstash', 1),\n",
              "  ('make', 1),\n",
              "  ('manager', 1),\n",
              "  ('map', 1),\n",
              "  ('matplotlib', 1),\n",
              "  ('member', 1),\n",
              "  ('meta', 1),\n",
              "  ('method', 1),\n",
              "  ('mining', 1),\n",
              "  ('model', 2),\n",
              "  ('monitor', 1),\n",
              "  ('month', 1),\n",
              "  ('monthscompany', 1),\n",
              "  ('motor', 1),\n",
              "  ('multiple', 2),\n",
              "  ('mysql', 1),\n",
              "  ('naa', 2),\n",
              "  ('name', 1),\n",
              "  ('natural_language', 1),\n",
              "  ('net', 1),\n",
              "  ('neural', 1),\n",
              "  ('neutral', 1),\n",
              "  ('nltk', 1),\n",
              "  ('node', 1),\n",
              "  ('number', 1),\n",
              "  ('numpy', 1),\n",
              "  ('open_cv', 1),\n",
              "  ('operation', 1),\n",
              "  ('option', 1),\n",
              "  ('order', 1),\n",
              "  ('organization', 2),\n",
              "  ('other', 1),\n",
              "  ('outdated', 1),\n",
              "  ('output', 1),\n",
              "  ('overview', 1),\n",
              "  ('panda', 1),\n",
              "  ('parse', 1),\n",
              "  ('pca', 1),\n",
              "  ('perform', 1),\n",
              "  ('personally', 1),\n",
              "  ('pii', 1),\n",
              "  ('pipeline', 1),\n",
              "  ('platform', 5),\n",
              "  ('plot', 1),\n",
              "  ('plotly', 1),\n",
              "  ('portfolio', 1),\n",
              "  ('position', 1),\n",
              "  ('positive_negative', 2),\n",
              "  ('precision', 1),\n",
              "  ('predefine', 1),\n",
              "  ('predictive', 3),\n",
              "  ('preform', 2),\n",
              "  ('present', 1),\n",
              "  ('process', 2),\n",
              "  ('processing', 1),\n",
              "  ('product', 2),\n",
              "  ('programming', 1),\n",
              "  ('project', 1),\n",
              "  ('push', 1),\n",
              "  ('python', 1),\n",
              "  ('qa', 1),\n",
              "  ('question', 5),\n",
              "  ('random_for', 1),\n",
              "  ('receive', 1),\n",
              "  ('recommendation', 1),\n",
              "  ('recommended', 1),\n",
              "  ('red', 2),\n",
              "  ('reduce', 1),\n",
              "  ('redundant', 1),\n",
              "  ('regression', 1),\n",
              "  ('regular', 1),\n",
              "  ('related', 2),\n",
              "  ('relevant', 2),\n",
              "  ('report', 2),\n",
              "  ('reporting', 1),\n",
              "  ('requirement', 1),\n",
              "  ('research', 1),\n",
              "  ('reservation', 1),\n",
              "  ('response', 1),\n",
              "  ('result', 2),\n",
              "  ('review', 8),\n",
              "  ('risk', 1),\n",
              "  ('rot', 1),\n",
              "  ('run', 2),\n",
              "  ('science', 3),\n",
              "  ('scikit_learn', 1),\n",
              "  ('scipy', 1),\n",
              "  ('scratch', 1),\n",
              "  ('search', 1),\n",
              "  ('security', 1),\n",
              "  ('sentiment', 4),\n",
              "  ('series', 1),\n",
              "  ('serve', 1),\n",
              "  ('service', 1),\n",
              "  ('simple', 1),\n",
              "  ('skill', 2),\n",
              "  ('social', 1),\n",
              "  ('solution', 1),\n",
              "  ('source', 2),\n",
              "  ('spacy', 1),\n",
              "  ('spend', 1),\n",
              "  ('sqlserver', 2),\n",
              "  ('standard', 1),\n",
              "  ('store', 1),\n",
              "  ('suite', 1),\n",
              "  ('survey', 3),\n",
              "  ('svm', 1),\n",
              "  ('synthesize', 1),\n",
              "  ('system', 2),\n",
              "  ('tag', 1),\n",
              "  ('tar', 2),\n",
              "  ('target', 1),\n",
              "  ('team', 1),\n",
              "  ('technique', 1),\n",
              "  ('technologie', 1),\n",
              "  ('technology', 5),\n",
              "  ('term', 1),\n",
              "  ('text', 4),\n",
              "  ('tfidf', 1),\n",
              "  ('time', 2),\n",
              "  ('tool', 8),\n",
              "  ('topic_modelle', 3),\n",
              "  ('topic_modelling', 2),\n",
              "  ('tree', 1),\n",
              "  ('trivial', 1),\n",
              "  ('understand', 2),\n",
              "  ('unstructured', 1),\n",
              "  ('usa', 1),\n",
              "  ('use', 2),\n",
              "  ('user', 3),\n",
              "  ('vader', 1),\n",
              "  ('various', 1),\n",
              "  ('vec', 2),\n",
              "  ('vehicle', 1),\n",
              "  ('vision', 1),\n",
              "  ('visualization', 2),\n",
              "  ('word', 4),\n",
              "  ('word_embedde', 1),\n",
              "  ('word_embedding', 1),\n",
              "  ('work', 1),\n",
              "  ('year', 1)]]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WQhp0h0w0Z09"
      },
      "outputs": [],
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=20, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=5,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "K71AZK-j07RL"
      },
      "outputs": [],
      "source": [
        "lda_model.save(\"model_lda_100.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc-MfWre083q",
        "outputId": "cbfd4050-f923-4661-c063-28cb66a4c9f5"
      },
      "outputs": [],
      "source": [
        "from gensim.models.ldamodel import LdaModel\n",
        "lda_model = LdaModel.load(\"model_lda_100.model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Rkp15NZ0-3C",
        "outputId": "7f794d75-f039-4c80-9cd4-90d100190e56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.189*\"date\" + 0.080*\"single\" + 0.034*\"machine\" + 0.034*\"classification\" + '\n",
            "  '0.029*\"learn\" + 0.019*\"remedy\" + 0.016*\"skilled\" + 0.013*\"tensorflow\" + '\n",
            "  '0.013*\"regression\" + 0.013*\"certification\"'),\n",
            " (1,\n",
            "  '0.047*\"job\" + 0.036*\"company\" + 0.030*\"manage\" + 0.029*\"operation\" + '\n",
            "  '0.026*\"ensure\" + 0.023*\"issue\" + 0.022*\"management\" + 0.019*\"schedule\" + '\n",
            "  '0.018*\"maintain\" + 0.018*\"project\"'),\n",
            " (2,\n",
            "  '0.109*\"datum\" + 0.057*\"use\" + 0.030*\"user\" + 0.029*\"different\" + '\n",
            "  '0.025*\"platform\" + 0.024*\"create\" + 0.024*\"cluster\" + 0.021*\"source\" + '\n",
            "  '0.020*\"table\" + 0.020*\"query\"'),\n",
            " (3,\n",
            "  '0.000*\"skill\" + 0.000*\"detail\" + 0.000*\"learn\" + 0.000*\"computer\" + '\n",
            "  '0.000*\"month\" + 0.000*\"technology\" + 0.000*\"datum\" + 0.000*\"algorithm\" + '\n",
            "  '0.000*\"use\" + 0.000*\"analytic\"'),\n",
            " (4,\n",
            "  '0.030*\"robotic\" + 0.009*\"passionate\" + 0.005*\"manipulate\" + '\n",
            "  '0.005*\"datamite\" + 0.003*\"advanced\" + 0.000*\"daysa_workshop\" + 0.000*\"real\" '\n",
            "  '+ 0.000*\"science\" + 0.000*\"machine\" + 0.000*\"savitribai_phule\"'),\n",
            " (5,\n",
            "  '0.190*\"electrical\" + 0.158*\"power\" + 0.135*\"maintenance\" + '\n",
            "  '0.119*\"engineering\" + 0.052*\"motor\" + 0.048*\"conduct\" + 0.041*\"point\" + '\n",
            "  '0.024*\"basic\" + 0.017*\"ssc\" + 0.016*\"detail\"'),\n",
            " (6,\n",
            "  '0.000*\"learn\" + 0.000*\"less\" + 0.000*\"year\" + 0.000*\"machine\" + '\n",
            "  '0.000*\"month\" + 0.000*\"deep\" + 0.000*\"datum\" + 0.000*\"skill\" + '\n",
            "  '0.000*\"detail\" + 0.000*\"science\"'),\n",
            " (7,\n",
            "  '0.170*\"business\" + 0.085*\"unit\" + 0.046*\"datum\" + 0.042*\"issue\" + '\n",
            "  '0.034*\"analysis\" + 0.029*\"drive\" + 0.027*\"expertise\" + 0.021*\"apply\" + '\n",
            "  '0.019*\"stage\" + 0.018*\"studio\"'),\n",
            " (8,\n",
            "  '0.086*\"detail\" + 0.074*\"month\" + 0.060*\"skill\" + 0.055*\"company\" + '\n",
            "  '0.047*\"year\" + 0.040*\"work\" + 0.034*\"description\" + 0.033*\"less\" + '\n",
            "  '0.028*\"education\" + 0.024*\"exprience\"'),\n",
            " (9,\n",
            "  '0.178*\"pune\" + 0.058*\"bank\" + 0.055*\"release\" + 0.052*\"private\" + '\n",
            "  '0.043*\"banking\" + 0.042*\"design\" + 0.036*\"limited\" + 0.026*\"global\" + '\n",
            "  '0.022*\"system\" + 0.019*\"team\"'),\n",
            " (10,\n",
            "  '0.077*\"management\" + 0.064*\"team\" + 0.041*\"report\" + 0.039*\"plan\" + '\n",
            "  '0.035*\"automation\" + 0.033*\"manager\" + 0.024*\"handle\" + 0.019*\"sale\" + '\n",
            "  '0.018*\"risk\" + 0.018*\"coordinate\"'),\n",
            " (11,\n",
            "  '0.121*\"hadoop\" + 0.117*\"datum\" + 0.087*\"hive\" + 0.042*\"distribution\" + '\n",
            "  '0.030*\"preparation\" + 0.024*\"spark\" + 0.023*\"special\" + 0.021*\"set\" + '\n",
            "  '0.020*\"data\" + 0.020*\"handle\"'),\n",
            " (12,\n",
            "  '0.050*\"project\" + 0.037*\"process\" + 0.032*\"quality\" + 0.032*\"client\" + '\n",
            "  '0.026*\"report\" + 0.023*\"testing\" + 0.022*\"customer\" + 0.021*\"company\" + '\n",
            "  '0.020*\"document\" + 0.020*\"work\"'),\n",
            " (13,\n",
            "  '0.082*\"database\" + 0.082*\"server\" + 0.066*\"use\" + 0.042*\"system\" + '\n",
            "  '0.034*\"sql\" + 0.029*\"application\" + 0.028*\"oracle\" + 0.028*\"environment\" + '\n",
            "  '0.027*\"developer\" + 0.027*\"script\"'),\n",
            " (14,\n",
            "  '0.118*\"build\" + 0.113*\"engineer\" + 0.057*\"feature\" + 0.048*\"aw\" + '\n",
            "  '0.041*\"project\" + 0.039*\"task\" + 0.038*\"regression\" + 0.037*\"selenium\" + '\n",
            "  '0.036*\"application\" + 0.031*\"person\"'),\n",
            " (15,\n",
            "  '0.000*\"pune\" + 0.000*\"css\" + 0.000*\"maharashtra\" + 0.000*\"project\" + '\n",
            "  '0.000*\"use\" + 0.000*\"technology\" + 0.000*\"jquery\" + 0.000*\"developer\" + '\n",
            "  '0.000*\"service\" + 0.000*\"information\"'),\n",
            " (16,\n",
            "  '0.000*\"employee\" + 0.000*\"datum\" + 0.000*\"learn\" + 0.000*\"month\" + '\n",
            "  '0.000*\"project\" + 0.000*\"develop\" + 0.000*\"management\" + 0.000*\"machine\" + '\n",
            "  '0.000*\"analytic\" + 0.000*\"science\"'),\n",
            " (17,\n",
            "  '0.000*\"serve\" + 0.000*\"leadership\" + 0.000*\"science\" + 0.000*\"detail\" + '\n",
            "  '0.000*\"question\" + 0.000*\"involve\" + 0.000*\"ie\" + 0.000*\"skill\" + '\n",
            "  '0.000*\"develop\" + 0.000*\"company\"'),\n",
            " (18,\n",
            "  '0.145*\"maintain\" + 0.093*\"system\" + 0.081*\"control\" + 0.074*\"engineer\" + '\n",
            "  '0.055*\"company\" + 0.053*\"management\" + 0.042*\"duty\" + 0.030*\"electronic\" + '\n",
            "  '0.025*\"proper\" + 0.021*\"product\"'),\n",
            " (19,\n",
            "  '0.051*\"testing\" + 0.051*\"project\" + 0.039*\"month\" + 0.035*\"system\" + '\n",
            "  '0.033*\"application\" + 0.029*\"description\" + 0.028*\"role\" + 0.023*\"window\" + '\n",
            "  '0.022*\"detail\" + 0.022*\"etl\"')]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "sLroO4Py1--a",
        "outputId": "a45f7558-0cb8-4ae8-d40c-1770e9a5f774"
      },
      "outputs": [],
      "source": [
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
        "vis"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "LDA.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "070b5a36b9737f3961041c61a6da21bcc71389dc32cf2d476b8b7b5f53c73875"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit (windows store)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
